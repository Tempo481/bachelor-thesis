\chapter{Einleitung}
\label{ch:intro}
OAuth2 als Spezifikation kann unter anderem dafür genutzt werden \linebreak \ac{HTTP}-Schnittstellen zu sichern. Es ist heutzutage praktisch Standard und hat eine Vielzahl von Einsatzzwecken, wie neben der Sicherung von Schnittstellen auch die Authentifizierung. Die meisten Konzerne setzen Implementierungen dieser Spezifikation ein, so auch beispielsweise Microsoft \citep{microsoftoauth2:2021:07}. Ein typischer Ablauf in OAuth2 ist folgendermaßen zu beschreiben:\smallskip

Ein Nutzer authentifiziert sich am Client-Computer und daraufhin erhält der OAuth2-Client von einem Autorisationsserver einen Token, mit dem er auf gesicherte Schnittstellen eines Ressource Servers zugreifen kann. Hierbei ist zu erwähnen, dass nutzerspezifische Attribute in den Token gemappt werden. Dies kann beispielsweise der Vor-und-Nachname sein, die E-Mail-Adresse, die Abteilung, in der der Nutzer arbeitet, sowie etwaige Rollen und Gruppenzugehörigkeiten. In dem Ressource Server ist es oftmals notwendig nach diesen Nutzerattributen zu autorisieren. Beispielsweise kann die Anforderung bestehen, dass ein Nutzer mit der Rolle \emph{ROLE\_ADMIN} oder ein Nutzer der in der Abteilung \emph{Human Ressources} arbeitet, Admin-Privilegien erhalten soll, das heißt auf Schnittstellen zugreifen kann, die voraussetzen das diese Attribute in dem Token vorhanden sind.\smallskip

Grundsätzlich lassen sich diese Zugriffsrichtlinien in dem Ressource Server selbst implementieren. Allerdings haben wir es in der Praxis in Firmen oftmals mit einer Vielzahl von Applikationen, das heißt Ressource Servern, zu tun die verschiedene Zugriffsrichtlinien haben und zudem mit verschiedenen Programmiersprachen und Frameworks geschrieben sind. Dies kann vor allem bei komplexen und sich häufig ändernden Zugriffsrichtlinien zum einen zu einem hohen Wartungsaufwand führen und zum anderen auch zu Sicherheitsrisiken führen. 
Unter anderem aus diesem Grund wurde \ac{OPA} entwickelt. Es entkoppelt die Zugriffskontrolle von dem Ressource Server als externes Programm in einer leicht verständlichen Programmiersprache, die ausschließlich für die Zugriffskontrolle zuständig ist. Wenn ein Ressource Server von einem Client eine HTTP-Anfrage mit einem validen Token erhält, sendet er diese Anfrage mit dem Token an den OPA-Service. In dem OPA-Service sind Richtlinien zur Zugriffskontrolle in der Programmiersprache Rego hinterlegt. Beispielsweise kann in dem OPA-Service eine Zugriffskontrolle hinterlegt sein, die besagt, dass auf die HTTP-GET-Schnittstelle mit dem Pfad /secretData nur Zugriff gewährleistet werden darf, wenn in dem Token das Schlüssel-Wert-Paar \emph{roles: ROLE\_ADMIN} hinterlegt ist. Falls dem so ist, würde der OPA-Service eine Zugriffserlaubnis an den Ressource Server zurücksenden, der wiederum dem Client entsprechend die Daten von der GET-Schnittstelle /secretData zusendet, da ja OPA evaluiert hat, dass dieser Token die nötigen Befugnisse verfügt und damit der Nutzer ordnungsgemäß autorisiert ist diese Schnittstelle aufzurufen. Ein weiterer Vorteil der Entkopplung von Zugriffskontrolle ist aus Sicht des Software-Engineering die Trennung der Zuständigkeiten (Separation of Concerns). 

%
% Section: Motivation
%
\section{Motivation}
\label{sec:intro:motivation}
%\graffito{Note: The content of this chapter is just some dummy text. It is not a real language.}
Ein Nachteil dieser Entkopplung speziell in OAuth2 Systemen ist der, dass der Ressource Server jedes Mal bei einkommenden HTTP-Anfragen dem OPA-Service die HTTP-Anfrage inklusive des Tokens zusenden muss, dieser den Token dekodieren, parsen und schlussendlich anhand dessen eine Zugriffsentscheidung evaluieren und dem Ressource Server zusenden muss. Das heißt es entsteht ein zusätzlicher Kommunikationsverkehr, was zu Performanceproblemen führen kann. Bei einer hohen Last auf Schnittstellen, werden diese in der Regel horizontal skaliert. Das bedeutet, falls eine Schnittstelle aufgrund zu hoher Last nicht mehr in akzeptabler Zeit HTTP-Anfragen beantworten kann, wird eine neue Instanz dieser Applikation auf einem zweiten Host erstellt und ein Loadbalancer sorgt dafür, dass die Last gleichmäßig verteilt wird und dadurch die Antwortzeiten möglichst niedrig gehalten werden \citep{kubernetes:2020}. Diese Metrik wird auch die Response Time genannt, also die Zeit vor dem Senden einer HTTP-Anfrage an den Server bis zum Eintreffen des letzten Bytes der Antwort des Servers \citep{jmeterglossary:2021}.\smallskip

Die Entwickler von Open Policy Agent geben an, dass anhand von durchgeführten Benchmarks Zugriffsentscheidungen in der Regel nur Rechenzeit im Bereich von unter einer Millisekunde benötigen \citep{opaperformance:2021:07}. In diesen Benchmarks wurden allerdings weder zu dekodierenden Tokens verwendet noch wurde auf die umso wichtigere Response Time eingegangen: Nämlich die Zeit, die gebraucht wird, wenn ein Client eine HTTP-Anfrage an einen Ressource Server sendet, dieser die Anfrage an den OPA-Service zur Evaluierung einer Zugriffsentscheidung sendet und schlussendlich der Ressource Server basierend auf der Zugriffsentscheidung des OPA-Services dem Client antwortet. Zudem ist ungewiss, wie sich externe Zugriffskontrolle mit OPA unter Last im Vergleich zur Zugriffskontrolle, die in dem Ressource Server selbst implementiert ist, verhält. Potenziell könnten nicht vertretbar hohe Latenzen entstehen, die entweder durch horizontale Skalierung gelöst werden müssen oder das Nutzererlebnis leidet unter hohen Antwortzeiten.\smallskip

In der Arbeit \emph{Verteilte Policy-basierte Autorisierung mit OAuth 2.0 und OpenID Connect} wurde behauptet, dass keine nennenswerte Latenz zwischen Ressource Server und OPA entsteht, wenn diese in einem Kubernetes Cluster ausgeführt werden und sich OPA als Sidecar in einem Pod mit dem Ressource Server befindet \citep{steinleitner:2020}. Hierauf wurde sich auf einen Artikel von Microsoft berufen \citep{sidecar:2017}. Diese Behauptung wurde allerdings nicht bewiesen, Performancetests hinsichtlich der Response Time beziehungsweise Latenz wurden nicht durchgeführt.

%
% Section: Ziele
%
\section{Vorgehensweise und Ergebnisse}
\label{sec:intro:goal}
Um den Einfluss von externer Zugriffskontrolle auf die Performance in\linebreak OAuth2 Systemen zu untersuchen, wurden zwei Ressource Server implementiert. In dem einen System wird die Zugriffskontrolle in dem Ressource Server selbst gehandhabt und in dem anderen wird sie entkoppelt durch den Open Policy Agent. 
Als Tool zur Generierung von Last und dem Messen und Protokollieren der Response Time wurde Apache JMeter verwendet. Neben dem Last-Test wurden zwei weitere Testpläne in JMeter erstellt. Ein Test zur Skalierbarkeit und ein Stress-Test. Bei dem Skalierbarkeitstest wird nicht eine gleichbleibende Last erzeugt, sondern es wird periodisch Last durch hinzukommende Threads erhöht, um zu sehen, inwiefern sich die Response Time bei hinzukommender Last erhöht. Diese Art des Tests ist aus wirtschaftlicher Sicht sinnvoll, denn anhand dessen lässt sich herleiten, wie sehr sich Antwortzeiten bei hinzukommender Anzahl von Nutzern erhöhen. Dadurch kann vorausgesehen werden, wann Ressource Server skaliert werden müssen, damit die Anfragen von Nutzern akzeptabel niedrige Antwortzeiten haben.\smallskip

Bei dem Stresstest wird eine hohe Last auf den Ressource Servern generiert mit dem Ziel herauszufinden, wie viele Nutzer der Ressource Server gleichzeitig bedienen kann bis entweder der Ressource Server vollkommen unerreichbar ist oder die Antwortzeiten unakzeptabel hoch werden. Diese drei Testpläne, Last-, Skalierbarkeit- und Stresstest wurden auf dem Ressource Server mit und ohne OPA-Service durchgeführt und die Resultate verglichen.\smallskip

Zudem wurden die jeweiligen Performancetests für das System mit OPA, einmal mit Kubernetes durchgeführt, wobei sich hier Ressource Server und OPA in einem Pod befinden, als auch ohne Kubernetes durchgeführt. Wenn sich zwei Container in einem Pod befinden, bezeichnet man dies als Sidecar-Muster. Hierbei teilen sich die Container Speicher- und Netzwerkressourcen \citep{sidecar:2017}.\smallskip

Bei zehn gleichzeitigen Threads (Lasttest) stellte es sich heraus, dass die Response Times bei dem System mit OPA durchschnittlich mehr als dreimal so hoch ausfielen. Außerdem fiel das System mit Open Policy Agent hier durch eine doppelt so hohe \ac{CPU}-Auslastung negativ auf im Vergleich zu dem System ohne externe Zugriffskontrolle. Zudem skaliert das System mit \ac*{OPA} deutlich schlechter, denn bei ansteigender Last auf bis zu 100 Nutzer stiegen die Response Times linear, während bei dem System ohne OPA diese konstant niedrig blieben. Unter starker Last war Open Policy Agent zeitweise nicht erreichbar für den Ressource Server. Es konnte also ein signifikanter Performancenachteil nachgewiesen werden, sowie eine Unerreichbarkeit von Open Policy Agent unter starker Last festgestellt werden. Die Hypothese, dass ein negativer Einfluss auf die Performance durch den zusätzlichen Kommunikationsaufwand der zwischen Server und \ac*{OPA} auftritt, entsteht, wurde bestätigt. Die Nutzung von Kubernetes hatte keine Verbesserung der Performance des Systems mit OPA zur Folge, sondern im Gegenteil, die Performance hat sich sogar verschlechtert. Die Behauptung, dass keine nennenswerte Latenz entsteht, wenn sich Ressource Server und OPA in einem Pod in einem Kubernetes Cluster befinden, wurde widerlegt. 

%
% Section: Struktur der Arbeit
%
\section{Gliederung}
\label{sec:intro:structure}
Zunächst werden in \autoref{sec:TechnischeGrundlagen} die benötigten technischen Grundlagen zusammengetragen. Darauf folgt \autoref{sec:Einfluss von externer Zugriffskontrolle auf die Performance in OAuth2 Systemen}, in dem die jeweiligen Ressource Server und die Performancetests, die mit Apache JMeter ausgeführt werden, beschrieben werden. In \autoref{AuswertungderPerformancetests} werden die Ergebnisse der Performancetests ausgewertet. In dem Kapitel Stand der Technik, \autoref{StandderTechnik}, werden verwandte Arbeiten diskutiert. Zum Schluss folgt eine Zusammenfassung und Ausblick, dies ist \autoref{Zusammenfassung}. 
