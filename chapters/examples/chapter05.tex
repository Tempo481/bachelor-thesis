\chapter{Stand der Technik}
Eric Speidel hat in seiner Bachelorarbeit ein Single Sign-On-System entwickelt und hierbei unter anderem auch OpenID Connect verwendet und Performancetests mit Apache JMeter auf geschützte Schnittstellen des Servers durchgeführt \citep{speidel:2017}. Als Metrik bei diesen Performancetests wurde aber nur die CPU-Auslastung betrachtet und für die Zugriffskontrolle des Servers wurde Open Policy Agent nicht verwendet. Anders als in dieser Arbeit, hat Eric Speidel zur Implementierung des Ressource Servers .NET Core von Microsoft verwendet, was vergleichbar mit dem Java-Framework Spring ist.\smallskip

Es wurde mittels Apache JMeter Last auf den Server erzeugt und die CPU-Auslastung des Servers mittels des Visual Studio 2017 Leistungsprofilers analysiert. Es ist davon auszugehen, dass Apache JMeter Last auf den Server erzeugt hat, indem es HTTP-Anfragen in einem Performancetest mit validen und in einem anderen Performancetest mit invalidem Token zu dem Server sendet. Bei den Performancetests mit validem Token wurden 100 Threads und 1000 Threads über einen Zeitraum von jeweils 30 Sekunden gestartet. Eric Speidel hat für einen kurzen Zeitraum eine maximale CPU-Auslastung von 10\% bei 100 Threads und 15\% bei 1000 Threads messen können, woraus er schließt, dass bei ansteigender Last, die CPU-Auslastung nicht linear steigt. Bei einem Performancetest mit invalidem Token und 1000 Threads konnte eine maximale CPU-Auslastung von 20\% festgestellt werden. Der nur kurzfristige Anstieg der CPU-Auslastung und das darauffolgende Absinken der CPU-Auslastung auf jeweils unter 10\% in allen drei Tests, erklärt sich Eric Speidel mit der ressourcenintensive Tokenvalidierung. Das nur eine relativ geringe CPU-Auslastung gemessen wurde, könnte damit begründet werden, dass die jeweiligen Performancetests nur für lediglich 30 Sekunden gestartet wurden. Eine Betrachtung der Latenz als Metrik in den Performancetests wurde nicht vorgenommen.\bigskip

In der Bachelorarbeit „Verteilte Policy-basierte Autorisierung mit OAuth 2.0 und OpenID Connect“, wurde ein System entwickelt, indem die Authentifizierung von Nutzern mit OpenID Connect und Keycloak und die Autorisierung der Nutzer durch Open Policy Agent geschieht \citep{steinleitner:2020}. Ein entscheidender Unterschied ist der, dass in dem System von Johannas Steinleitner der Ressource Server nicht die JSON Web Token validiert, sondern diese Aufgabe Open Policy Agent übernimmt. Open Policy Agent bietet zwar Unterstützung für die Validierung von JSON Web Token, aber ein Nachteil hierbei ist, dass bei Anfragen auf den Ressource Server mit invalidem Token diese Anfragen dennoch Open Policy Agent zugesendet werden, der wiederrum den Zugriff ablehnt, nachdem es den Token validiert hat. Wenn allerdings der Ressource Server die Validierung der Token übernimmt, würde bei dem Eintreffen von invalidem Token gar keine Kommunikation zwischen Server und Open Policy Agent auftreten, was wiederrum der Performance zugutekommt. Etwaige Performancetests hat Johannes Steinleitner nicht durchgeführt.\bigskip

Die Entwickler von Open Policy Agent haben selbst Performancetests durchgeführt, wobei sie zu dem Ergebnis gekommen sind, dass Open Policy Agent Zugriffsentscheidungen in der Regel innerhalb von einer Millisekunde evaluiert \citep{opaperformance:2021:07}. Um dies zu zeigen, wurden Benchmarks durchgeführt, in denen Zugriffsentscheidungen evaluiert werden und die Rechenzeit für die Evaluation anhand einer programmierten Zugriffsrichtlinie gemessen wird.\smallskip

In diesen Tests wurde die Zeit gemessen, um eine Zugriffsentscheidung für eine rollenbasierte Zugriffskontrolle (engl. Role Based Access Control – RBAC) zu evaluieren, wobei hier die Input-Daten schon in der Rego-Datei in dem die Zugriffskontrolle programmiert ist, vorhanden sind \citep{oparbacperformance:2021}. Hierbei wurde eine positive Zugriffsentscheidung in 605.076µs und eine negative Zugriffsentscheidung in 318.047µs getroffen, das heißt jeweils unter einer Millisekunde und damit aus Performancesicht in den aller meisten Anwendungsszenarien kein Problem.\smallskip

Allerdings sind hier die Input-Daten schon in der Rego-Datei hinterlegt, während im Produktionseinsatz diese dem OPA-Service durch den Server per HTTP zugesendet werden. Dies wurde in den Tests von Open Policy Agent nicht berücksichtigt. Hier geht es allein um die reine Rechenzeit, die benötigt wird, um eine Zugriffsentscheidung innerhalb des OPA-Service zu evaluieren. Jeglicher Zeitaufwand, der durch die HTTP-Kommunikation zwischen Server und OPA-Service zustande kommt, wird nicht berücksichtigt.\smallskip

Zudem sind die Input-Daten für den OPA-Service in OAuth2-Systemen kodierte JSON Web Token, was in den von Open Policy Agent durchgeführten Tests nicht der Fall ist. JSON Web Token können umfangreich sein, da neben dem Header, der Signatur und Pflicht-Claims, auch alle Nutzerinformationen in den Payload gemappt werden wie beispielsweise im Falle eines Mitarbeiters in einer Firma der Vor-und-Nachname, E-Mail-Adresse, Abteilung, Position, Büro, Standort sowie Gruppen-und-Rollenzugehörigkeiten. Zudem müssen JSON Web Token dekodiert werden, damit Open Policy Agent ihren Inhalt in JSON interpretieren kann, was zusätzliche Rechenzeit verursacht. 
In den Performance Tests von Open Policy Agent wurde also weder die Kommunikation zwischen Server und OPA-Service betrachtet noch Zugriffsentscheidungen anhand von zu dekodierenden JSON Web Tokens getroffen. Zudem wurde nicht getestet, wie sich ein Server, der die Zugriffskontrolle entkoppelt mit OPA, unter Last verhält und es wurde kein Vergleich gezogen, inwiefern sich die Performance im Vergleich zu einem Server ohne OPA verhält, da die Zugriffskontrolle natürlich auch in dem Server selbst implementiert werden kann. 
